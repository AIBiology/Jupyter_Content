{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to artificial neural networks\n",
    "\n",
    "This notebook begins a new unit on artificial neural networks (ANNs or just \"neural nets\" for short).  Neural nets provide an extremely flexible approach for solving a wide range of data analysis problems. From a high-level view, neural nets are conceptually quite simple, but, as we will see, first appearances can be deceiving.  We will build our understanding of neural nets slowly, by carefully investigating one piece at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implementing a neuron.\n",
    "\n",
    "<div>\n",
    "<img src=\"attachment:image-6.png\" width=\"228\" />\n",
    "</div>\n",
    "\n",
    "We have now seen the basic conceptual design of artificial neurons, illustrated above.  To review, each neuron has:\n",
    "\n",
    "* One or more scalar inputs ($x_1$, $x_2$, etc.).\n",
    "* Scalar values called \"weights\" that multiply the inputs ($w_1$, $w_2$, etc.).\n",
    "* A scalar value called the \"bias\" ($b$).\n",
    "* A summer that adds the weighted inputs and the bias to generate the neuron's output.\n",
    "\n",
    "The weights and bias are the _parameters_ of the neuron.\n",
    "\n",
    "As an exercise, try implementing a single artificial neuron using the inputs and parameters defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4])\n",
    "w = np.array([0.472898163, 0.2364490815, 0.157632721, 0.11822454075])\n",
    "b = 1.25\n",
    "\n",
    "# Given the input x and provided parameter values, what is the output of the neuron?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write this a different way and see if this reminds us of anything...\n",
    "\n",
    "$$ y = b + w_1x_1 + w_2x_2 + ... + w_px_p $$\n",
    "\n",
    "Ringing any bells? \n",
    "\n",
    "**A network with a single neuron is essentially a linear regression.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fitting a complete, single-neuron network.\n",
    "\n",
    "<div>\n",
    "<img src=\"attachment:image.png\" width=\"228\" />\n",
    "</div>\n",
    "\n",
    "Now that we have a basic understanding of the components of an artificial neuron, let's try creating and fitting the simplest possible neural network: a single neuron with a single input.  Due to time constraints, we will not do this from scratch (although doing so is a valuable exercise and I encourage you to try it).  Instead, we will rely on the Python library [Keras](https://keras.io/), to do most of the heavy lifting for us.\n",
    "\n",
    "Note that there are many alternatives to Keras and you might find that one or more of these alternatives fit your use case or preferences better.  Software for neural nets and deep learning is rapidly evolving, so explore your options!\n",
    "\n",
    "### a. Build a reference regression model using `sklearn`\n",
    "\n",
    "Let's return to the dataset we used in [07_Intro_sklearn_student.ipynb](07_Intro_sklearn_student.ipynb). This was a simulated dataset for linear regression, where we generated the data using the formula $y=2x+1 + Error $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make and plot the data\n",
    "rng = np.random.RandomState(42)\n",
    "x = 10 * rng.rand(50)\n",
    "y = 2*x - 1 + rng.randn(50)\n",
    "\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the X and fit the LinearRegression model\n",
    "X = x[:,np.newaxis]\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X,y)\n",
    "\n",
    "# Create xfit and yfit to plot the result\n",
    "xfit = np.linspace(-1,11)\n",
    "Xfit = xfit[:,np.newaxis]\n",
    "yfit = model.predict(Xfit)\n",
    "\n",
    "# Visualize the results\n",
    "plt.scatter(x,y)  # Scatter plot of our training data\n",
    "plt.scatter(xfit,yfit)  # Our linear model\n",
    "\n",
    "print(f'R^2: {model.score(X,y)}')\n",
    "print(f'Slope: {model.coef_}, Intercept: {model.intercept_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Translate the model to a neural network using `keras`\n",
    "\n",
    "Now, let's attempt to reproduce our regression analysis in the context of fitting a neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import keras\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the details here:\n",
    " * As with `sklearn` we are starting off by defining a `model`\n",
    " * In this case, we use the `keras.Sequential` class, used to make layered networks. \n",
    "     * For this example, we are using a single layer.\n",
    " * We add a layer using the `layers.Dense` class. \n",
    "     * A dense layer in a neural network means that every neuron is connected to every input (we only have one neuron and 1 input)\n",
    "     * We construct this one layers saying that it has 1 neuron and gets a 1\n",
    "     * To be able to see the `model.summary()` we need to specify the input shape.\n",
    "     \n",
    " * The model summary shows a text view of the \"network\" we have defined.\n",
    "   * Our network has one, dense layer\n",
    "   * It outputs one thing\n",
    "   * The layer, and the total model, have 2 parameters (slope and intercept)\n",
    "   \n",
    "Next we compile the model, a needed step where we can specify a loss function, optimizer and metrics we want to track during training.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model--a necessary step with Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can fit the model\n",
    "#  Note: I've set verbose=0 so we don't get thousands of lines of output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the code from above...\n",
    "xfit = np.linspace(-1,11)\n",
    "Xfit = xfit[:,np.newaxis]\n",
    "yfit = model.predict(Xfit)\n",
    "\n",
    "# Visaulize the results\n",
    "plt.scatter(x,y)  # Scatter plot of our training data\n",
    "plt.scatter(xfit,yfit)  # Our linear model\n",
    "\n",
    "# Get the predicted ys for each X (rather than the yfit used for the plot) \n",
    "y_pred = model.predict(X)\n",
    "print(f'R_2: {r2_score(y, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
